---
layout: post
title: "Part 2 - Application: MNIST"
date: 2017-06-15
author: pierre
tab: blog
comments: true
---
In [part 1]({{ site.baseurl }}{% post_url 2017-06-15-part1-computational-graphs %}), we have create a fully functional library which is able to create and train neural networks using computational. We used on very simple examples. Today, we are going to try it on a more serious problem: character recognition.

We are going to use a well-known database in the machine learning and deep learning world named MNIST. The database is available on [Yann LeCun's website](http://yann.lecun.com/exdb/mnist/). If you read a bit about neural networks before you should have already seen his name. He is a French scientist who is one of the pioneers of neural networks and inventors of convolutional neural networks and he is now the director of AI at Facebook.

Character recognition is an emblematic problem for two reasons. Firstly, it is one of the first successes and industrial applications of neural networks. It was used since the 90's to read checks. Secondly, computer vision has always been a leading application domain for neural networks.

In this part, we are going to briefly discover the MNIST database then, we are going to train some networks on it and finally, we are going to explore a bit how a neural network works. 

<!--more-->
# MNIST database

Firstly, you should download the four files named "train-images-idx3-ubyte.gz", "train-labels-idx1-ubyte.gz", "t10k-images-idx3-ubyte.gz", "t10k-labels-idx1-ubyte.gz". Then create a folder examples/mnist/mnist and uncompress them in the latter. If you have not already a file archiver, I can advise you to use [7-zip](http://www.7-zip.org/) for Windows, [The Unarchiver](https://itunes.apple.com/fr/app/the-unarchiver/id425424353?mt=12) for MacOS, on Linux you should already have one.

You can read the full specification on the database's page. But it is not necessary, I have already written a script to read the database for you. You should only know that the database is separated on two parts : the training set and the test set. The training set contains 60 000 labelled images and we are going to use it to train the network. The test set contains only 10 000 labelled images and we are going to use it only to test the network, not to train it. It is very important to keep separated the two parts otherwise, your accuracy would be largely overestimated.

# Training

# Visualization

## Weights

## Deep features

# To go further

Some problems to have fun:
* Try to find the best architecture and parameters to achieve the highest accuracy on the test set.
<a href="#clue1" data-toggle="collapse">Clues</a>
<div id="clue1" class="collapse">
On his [page](http://yann.lecun.com/exdb/mnist/index.html) Yann LeCun report results for different models including feedforward neural networks. It can gives you some ideas for the architectures. My best accuracy is 97.7%, try to beat it! You will surely overfit, maybe you can look at regularization to improve your results.
</div>